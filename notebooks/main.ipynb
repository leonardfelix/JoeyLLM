{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "201b41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ebea97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from model import JoeyLLM\n",
    "from data import get_dataloader\n",
    "from utils.logger import wandbLogger\n",
    "from train.trainer import  Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6715c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go UP one level to find the conf directory\n",
    "with hydra.initialize(config_path=\"../configs\", version_base=None):\n",
    "    cfg = hydra.compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a004edc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded Config:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"âœ… Loaded Config:\")\n",
    "\n",
    "wandbLogger.set_mode(cfg.wandb.mode)\n",
    "\n",
    "logger = wandbLogger(\n",
    "    project_name=cfg.wandb.project,\n",
    "    config=OmegaConf.to_container(cfg, resolve=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba43683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remote/u1138167/JoeyLLM/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"ðŸ“¦ Loading Dataset...\")\n",
    "dataloader = get_dataloader(\n",
    "    data_path=cfg.data.data_path,\n",
    "    chunk_size=cfg.data.chunk_size,\n",
    "    buffer_text_size=cfg.data.buffer_text_size,\n",
    "    batch_size=cfg.data.batch_size,\n",
    "    num_workers=cfg.data.num_workers\n",
    ")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07053709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Got batch with shape: torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "# Testing dataloader\n",
    "for batch in dataloader:\n",
    "    print(\"âœ… Got batch with shape:\", batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed16ff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Initializing Model...\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ§  Initializing Model...\")\n",
    "model = JoeyLLM(\n",
    "    vocab_size=cfg.model.vocab_size,\n",
    "    max_seq_len=cfg.model.max_seq_len,\n",
    "    embed_dim=cfg.model.embed_dim,\n",
    "    num_layers=cfg.model.num_layers,\n",
    "    num_heads=cfg.model.num_heads,\n",
    "    dropout=cfg.model.dropout,\n",
    ")\n",
    "logger.watch_model(model, log=\"all\", log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ed1fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Loading Optimizer\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print(\"ðŸ“ˆ Loading Optimizer\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), weight_decay=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0f8f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Launching Trainer...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"ðŸš€ Launching Trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=None,\n",
    "    logger=None,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    num_epochs=1,\n",
    "    checkpoint_path=\"checkpoints/checkpoint.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.finish()\n",
    "print(\"âœ… Training Done!\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
