{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "201b41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ebea97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "# from model import JoeyLLM\n",
    "from data import get_dataloader\n",
    "from utils.logger import wandbLogger\n",
    "# from train.trainer import  Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6715c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go UP one level to find the conf directory\n",
    "with hydra.initialize(config_path=\"../configs\", version_base=None):\n",
    "    cfg = hydra.compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a004edc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded Config:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"âœ… Loaded Config:\")\n",
    "\n",
    "wandbLogger.set_mode(cfg.wandb.mode)\n",
    "\n",
    "logger = wandbLogger(\n",
    "    project_name=cfg.wandb.project,\n",
    "    config=OmegaConf.to_container(cfg, resolve=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba43683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Loading Dataset...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"ðŸ“¦ Loading Dataset...\")\n",
    "dataloader = get_dataloader(\n",
    "    data_path=cfg.data.data_path,\n",
    "    chunk_size=cfg.data.chunk_size,\n",
    "    buffer_text_size=cfg.data.buffer_text_size,\n",
    "    batch_size=cfg.data.batch_size,\n",
    "    num_workers=cfg.data.num_workers\n",
    ")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07053709",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing dataloader\n",
    "    for batch in dataloader:\n",
    "        print(\"âœ… Got batch with shape:\", batch.shape)\n",
    "        break\n",
    "    \n",
    "    print(\"ðŸ§  Initializing Model...\")\n",
    "    model = JoeyLLM(\n",
    "        vocab_size=cfg.model.vocab_size,\n",
    "        max_seq_len=cfg.model.max_seq_len,\n",
    "        embed_dim=cfg.model.embed_dim,\n",
    "        num_layers=cfg.model.num_layers,\n",
    "        num_heads=cfg.model.num_heads,\n",
    "        dropout=cfg.model.dropout,\n",
    "    )\n",
    "    \n",
    "    logger.watch_model(model, log=\"all\", log_freq=10)\n",
    "\n",
    "    print(\"ðŸ“ˆ Loading Optimizer\")\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9, 0.95), weight_decay=0.1)\n",
    "\n",
    "\n",
    "    print(\"ðŸš€ Launching Trainer...\")\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        dataloader=dataloader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=None,\n",
    "        logger=None,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.fit(\n",
    "        num_epochs=1,\n",
    "        checkpoint_path=\"checkpoints/checkpoint.pth\"\n",
    "    )\n",
    "    \n",
    "    logger.finish()\n",
    "\n",
    "    print(\"âœ… Training Done!\")   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
